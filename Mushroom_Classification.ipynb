{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.7.0 64-bit"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.0"
    },
    "interpreter": {
      "hash": "cde3e89a557c46231f8d7b996aefd592c8a14cc08d4c94faa8758a36e2ea75ba"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZPF6VBSixy3",
        "outputId": "8e74046e-8301-4361-cb1a-4473d9938637"
      },
      "source": [],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.15\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/2b/e3af15221da9ff323521565fa3324b0d7c7c5b1d7a8ca66984c8d59cb0ce/tensorflow-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (412.3MB)\n",
            "\u001b[K     |████████████████████████████████| 412.3MB 20kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.12.0)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.36.2)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.34.1)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.12.1)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 28.3MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.1.2)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (3.12.4)\n",
            "Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.19.5)\n",
            "Collecting keras-applications>=1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.0MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (3.3.0)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.2.0)\n",
            "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.8.1)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 11.4MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (57.0.0)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.3.4)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (4.0.1)\n",
            "Requirement already satisfied, skipping upgrade: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow==1.15) (1.5.2)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.7.4.3)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.4.1)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp37-none-any.whl size=7557 sha256=805ad9971278ae2da44a2242c066a3f38bead4fb691a9d00b6c05f3a13ee7231\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow-probability 0.12.1 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: kapre 0.3.5 has requirement tensorflow>=2.0.0, but you'll have tensorflow 1.15.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: gast, tensorboard, keras-applications, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: gast 0.4.0\n",
            "    Uninstalling gast-0.4.0:\n",
            "      Successfully uninstalled gast-0.4.0\n",
            "  Found existing installation: tensorboard 2.5.0\n",
            "    Uninstalling tensorboard-2.5.0:\n",
            "      Successfully uninstalled tensorboard-2.5.0\n",
            "  Found existing installation: tensorflow-estimator 2.5.0\n",
            "    Uninstalling tensorflow-estimator-2.5.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.5.0\n",
            "  Found existing installation: tensorflow 2.5.0\n",
            "    Uninstalling tensorflow-2.5.0:\n",
            "      Successfully uninstalled tensorflow-2.5.0\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGAWrIpf2nCZ"
      },
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import PCA"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9VdSDSf2oQB",
        "outputId": "171f0257-cafc-43a5-b010-3772e99ea977"
      },
      "source": [
        "df = pd.read_csv('classification.csv')\n",
        "print(df.columns)\n",
        "new_df = df[['cap-shape', 'cap-color', 'odor','stalk-color-above-ring',\n",
        "             'stalk-color-below-ring', 'veil-color', 'ring-number', 'habitat']]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['class', 'cap-shape', 'cap-surface', 'cap-color', 'bruises', 'odor',\n",
            "       'stalk-shape', 'stalk-root', 'stalk-surface-above-ring',\n",
            "       'stalk-surface-below-ring', 'stalk-color-above-ring',\n",
            "       'stalk-color-below-ring', 'veil-type', 'veil-color', 'ring-number',\n",
            "       'ring-type', 'spore-print-color', 'population', 'habitat'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWQFbZsu2pcc"
      },
      "source": [
        "def  cap_shape_feature_transform(cap_shape):\n",
        "  cap_shape_list = []\n",
        "  for cap_shapes in cap_shape:\n",
        "    cap_shapez = 0\n",
        "    if (cap_shapes is 'b'):\n",
        "      cap_shapez = 1 \n",
        "    elif (cap_shapes is 'c'):\n",
        "      cap_shapez = 2 \n",
        "    elif (cap_shapes is 'x'):\n",
        "      cap_shapez = 3 \n",
        "    elif (cap_shapes is 'f'):\n",
        "      cap_shapez = 4 \n",
        "    elif (cap_shapes is 'k'):\n",
        "      cap_shapez = 5 \n",
        "    elif (cap_shapes is 's'):\n",
        "      cap_shapez = 6 \n",
        "    cap_shape_list.append(cap_shapez)\n",
        "  return pd.DataFrame(data=cap_shape_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcc047eB2sOs"
      },
      "source": [
        "def odor_feature_transform(odor):\n",
        "    odor_list = []\n",
        "    for odor_type in odor:\n",
        "        odor_types = 0\n",
        "        if (odor_type is 'a'):\n",
        "            odor_types = 1\n",
        "        elif (odor_type is 'l'):\n",
        "            odor_types = 2\n",
        "        elif (odor_type is 'c'):\n",
        "            odor_types = 3\n",
        "        elif (odor_type is 'y'):\n",
        "            odor_types = 4\n",
        "        elif (odor_type is 'f'):\n",
        "            odor_types = 5\n",
        "        elif (odor_type is 'm'):\n",
        "            odor_types = 6\n",
        "        elif (odor_type is 'n'):\n",
        "            odor_types = 7\n",
        "        elif (odor_type is 'p'):\n",
        "            odor_types = 8\n",
        "        elif (odor_type is 's'):\n",
        "            odor_types = 9\n",
        "        odor_list.append(odor_types)\n",
        "    return pd.DataFrame(data=odor_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYGKSbnZ2763"
      },
      "source": [
        "def habitat_transform(habitat):\n",
        "  habitat_list = []\n",
        "  for habitat_type in habitat:\n",
        "    habitat_types = 0\n",
        "    if (habitat_type is 'g'):\n",
        "      habitat_types = 1\n",
        "    elif (habitat_type is 'l'):\n",
        "      habitat_types = 2\n",
        "    elif (habitat_type is 'm'):\n",
        "      habitat_types = 3\n",
        "    elif (habitat_type is 'p'):\n",
        "      habitat_types = 4\n",
        "    elif (habitat_type is 'u'):\n",
        "      habitat_types = 5\n",
        "    elif (habitat_type is 'w'):\n",
        "      habitat_types = 6\n",
        "    elif (habitat_type is 'd'):\n",
        "      habitat_types = 7\n",
        "    habitat_list.append(habitat_types)\n",
        "\n",
        "  return pd.DataFrame(data=habitat_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bEs-iC_U28cl",
        "outputId": "7f6a4071-c472-4a57-c784-7f6b3359de93"
      },
      "source": [
        "#derived features\n",
        "new_df['cap-shape'] = cap_shape_feature_transform(new_df['cap-shape'])\n",
        "new_df['odor'] = odor_feature_transform(new_df['odor'])\n",
        "new_df['habitat'] = habitat_transform(new_df['habitat'])\n",
        "\n",
        "#normalize data\n",
        "new_df = MinMaxScaler().fit_transform(new_df)\n",
        "new_df = PCA(n_components=4).fit_transform(new_df)\n",
        "\n",
        "target = df['class']\n",
        "target\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       p\n",
              "1       e\n",
              "2       e\n",
              "3       p\n",
              "4       e\n",
              "       ..\n",
              "8119    e\n",
              "8120    e\n",
              "8121    e\n",
              "8122    p\n",
              "8123    e\n",
              "Name: class, Length: 8124, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecptFgk72980"
      },
      "source": [
        "#split data\n",
        "x_train, x_test, y_train, y_test = train_test_split(new_df, target, test_size=0.3)\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.14)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0Mk1H9f2_kp"
      },
      "source": [
        "y_train = y_train.values.reshape(-1,1)\n",
        "y_test = y_test.values.reshape(-1,1)\n",
        "y_val = y_val.values.reshape(-1,1)\n",
        "encoder = OneHotEncoder().fit(y_train)\n",
        "y_train = encoder.transform(y_train).toarray()\n",
        "y_test = encoder.transform(y_test).toarray()\n",
        "y_val = encoder.transform(y_val).toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dk0JNceM3BuI"
      },
      "source": [
        "x_train, x_test, x_val = x_train.astype('float32'), x_test.astype('float32'), x_val.astype('float32')\n",
        "y_train, y_test, y_val= y_train.astype('float32'), y_test.astype('float32'), y_val.astype('float32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-ZMoXSL3bZS"
      },
      "source": [
        "epoch = 2500\n",
        "learning_rate = 0.1\n",
        "n_features = x_train.shape[1]\n",
        "n_class = y_train.shape[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmPYYmKC3dMT"
      },
      "source": [
        "layer = {\n",
        "    'input': n_features,\n",
        "    'hidden1': 64,\n",
        "    'hidden2': 32,\n",
        "    'output' : n_class\n",
        "}\n",
        "parameters = {\n",
        "    'W1': tf.Variable(tf.random_normal([layer['input'] , layer['hidden1']])),\n",
        "    'W2': tf.Variable(tf.random_normal([layer['hidden1'] , layer['hidden2']])),\n",
        "    'W3': tf.Variable(tf.random_normal([layer['hidden2'] , layer['output']])),\n",
        "\n",
        "    'B1': tf.Variable(tf.random_normal([layer['hidden1']])),\n",
        "    'B2': tf.Variable(tf.random_normal([layer['hidden2']])),\n",
        "    'B3': tf.Variable(tf.random_normal([layer['output']])),\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZ1et9Fz3cwg"
      },
      "source": [
        "input_tensor = tf.placeholder(tf.float32,shape=[None, layer['input']]) \n",
        "label_tensor = tf.placeholder(tf.float32,shape=[None , layer['output']]) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "It-x5bB05q5V"
      },
      "source": [
        "def forward(input_tensor):\n",
        "  a1 = tf.matmul(input_tensor, parameters['W1']) + parameters['B1']\n",
        "  z1 = tf.nn.tanh(a1)\n",
        "\n",
        "  a2 = tf.matmul(z1, parameters['W2']) + parameters['B2']\n",
        "  z2 = tf.nn.tanh(a2)\n",
        "\n",
        "  a3 = tf.matmul(z2, parameters['W3']) + parameters['B3']\n",
        "  z3 = tf.nn.softmax(a3)\n",
        "\n",
        "  return a3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1njbZAuQX5Ai"
      },
      "source": [
        "saver = tf.train.Saver()\n",
        "best_loss = float('inf')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNhztNVtiF6O",
        "outputId": "7a9d3392-4a8f-473b-968f-d40e00ca7e23"
      },
      "source": [
        "  logits_tensor = forward(input_tensor)\n",
        "  loss_tensor = tf.reduce_mean(0.5 * (label_tensor - logits_tensor)**2)\n",
        "  #argmax> misal punya 1 output one hot encoder vector misal [0.8, 0.1, 0,1] argmax bakal\n",
        "  #return index yg elemennya terbesar\n",
        "  #tf.equal > itng brp yg equal > krn hasilnya booelan di cast jd float\n",
        "  true_preds_tensor = tf.equal(\n",
        "      tf.argmax(logits_tensor, axis=1), tf.argmax(label_tensor, axis=1))\n",
        "  acc_tensor = tf.reduce_mean(tf.cast(true_preds_tensor, tf.float32))\n",
        "  \n",
        "  optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss_tensor)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTz0Pv8P5tUA",
        "outputId": "d4ad03a9-c3b7-49fb-9d72-57cc9e8ad85e"
      },
      "source": [
        "with tf.Session() as sess:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  feed_train = {\n",
        "    input_tensor: x_train,\n",
        "      label_tensor: y_train\n",
        "  }\n",
        "  feed_test = {\n",
        "    input_tensor : x_test,\n",
        "    label_tensor : y_test\n",
        "  }\n",
        "  feed_val = {\n",
        "    input_tensor : x_val,\n",
        "    label_tensor : y_val\n",
        "  }\n",
        "  for i in range(epoch):\n",
        "    sess.run(optimizer, feed_dict = feed_train)\n",
        "    loss = sess.run(loss_tensor, feed_dict =feed_train)\n",
        "    if i % 25==0:\n",
        " \n",
        "        print('Epoch: {}, Error: {}'.format(i, loss))\n",
        "    if i == 125:\n",
        "      val_loss = sess.run(loss_tensor, feed_dict = feed_test)\n",
        "      saver.save(sess, './model.ckpt')\n",
        "\n",
        "    if i % 125==0:\n",
        "      val_loss = sess.run(loss_tensor, feed_dict = feed_test)\n",
        "      if val_loss < best_loss:\n",
        "        best_loss = val_loss\n",
        "        saver.save(sess, './best_model.ckpt')\n",
        "\n",
        "  val_acc = sess.run(acc_tensor, feed_dict=feed_test)\n",
        "  print('Accuracy : {}'.format(val_acc * 100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0, Error: 10.881184577941895\n",
            "Epoch: 25, Error: 0.17806126177310944\n",
            "Epoch: 50, Error: 0.11175516247749329\n",
            "Epoch: 75, Error: 0.09001538157463074\n",
            "Epoch: 100, Error: 0.07855618745088577\n",
            "Epoch: 125, Error: 0.07093598693609238\n",
            "Epoch: 150, Error: 0.06529542058706284\n",
            "Epoch: 175, Error: 0.060863375663757324\n",
            "Epoch: 200, Error: 0.05725749209523201\n",
            "Epoch: 225, Error: 0.054251257330179214\n",
            "Epoch: 250, Error: 0.051692619919776917\n",
            "Epoch: 275, Error: 0.04947575554251671\n",
            "Epoch: 300, Error: 0.047527141869068146\n",
            "Epoch: 325, Error: 0.045795198529958725\n",
            "Epoch: 350, Error: 0.04424243047833443\n",
            "Epoch: 375, Error: 0.042840223759412766\n",
            "Epoch: 400, Error: 0.04156557843089104\n",
            "Epoch: 425, Error: 0.04039924964308739\n",
            "Epoch: 450, Error: 0.039324741810560226\n",
            "Epoch: 475, Error: 0.038327861577272415\n",
            "Epoch: 500, Error: 0.03739628195762634\n",
            "Epoch: 525, Error: 0.036519329994916916\n",
            "Epoch: 550, Error: 0.03568779677152634\n",
            "Epoch: 575, Error: 0.03489384427666664\n",
            "Epoch: 600, Error: 0.03413086012005806\n",
            "Epoch: 625, Error: 0.03339352458715439\n",
            "Epoch: 650, Error: 0.03267781436443329\n",
            "Epoch: 675, Error: 0.03198125213384628\n",
            "Epoch: 700, Error: 0.03130284696817398\n",
            "Epoch: 725, Error: 0.030643068253993988\n",
            "Epoch: 750, Error: 0.030003486201167107\n",
            "Epoch: 775, Error: 0.02938605286180973\n",
            "Epoch: 800, Error: 0.028792526572942734\n",
            "Epoch: 825, Error: 0.02822401002049446\n",
            "Epoch: 850, Error: 0.027680760249495506\n",
            "Epoch: 875, Error: 0.027162354439496994\n",
            "Epoch: 900, Error: 0.026667781174182892\n",
            "Epoch: 925, Error: 0.026195848360657692\n",
            "Epoch: 950, Error: 0.02574511617422104\n",
            "Epoch: 975, Error: 0.02531415969133377\n",
            "Epoch: 1000, Error: 0.02490156702697277\n",
            "Epoch: 1025, Error: 0.024506019428372383\n",
            "Epoch: 1050, Error: 0.02412629872560501\n",
            "Epoch: 1075, Error: 0.02376129850745201\n",
            "Epoch: 1100, Error: 0.023410063236951828\n",
            "Epoch: 1125, Error: 0.02307167835533619\n",
            "Epoch: 1150, Error: 0.022745421156287193\n",
            "Epoch: 1175, Error: 0.02243056334555149\n",
            "Epoch: 1200, Error: 0.022126441821455956\n",
            "Epoch: 1225, Error: 0.02183251827955246\n",
            "Epoch: 1250, Error: 0.021548274904489517\n",
            "Epoch: 1275, Error: 0.021273208782076836\n",
            "Epoch: 1300, Error: 0.021006913855671883\n",
            "Epoch: 1325, Error: 0.020749026909470558\n",
            "Epoch: 1350, Error: 0.020499208942055702\n",
            "Epoch: 1375, Error: 0.020257186144590378\n",
            "Epoch: 1400, Error: 0.020022708922624588\n",
            "Epoch: 1425, Error: 0.019795536994934082\n",
            "Epoch: 1450, Error: 0.019575459882616997\n",
            "Epoch: 1475, Error: 0.01936226524412632\n",
            "Epoch: 1500, Error: 0.019155722111463547\n",
            "Epoch: 1525, Error: 0.01895558461546898\n",
            "Epoch: 1550, Error: 0.018761608749628067\n",
            "Epoch: 1575, Error: 0.018573535606265068\n",
            "Epoch: 1600, Error: 0.01839110441505909\n",
            "Epoch: 1625, Error: 0.01821405440568924\n",
            "Epoch: 1650, Error: 0.018042122945189476\n",
            "Epoch: 1675, Error: 0.01787506975233555\n",
            "Epoch: 1700, Error: 0.017712650820612907\n",
            "Epoch: 1725, Error: 0.017554698511958122\n",
            "Epoch: 1750, Error: 0.017400983721017838\n",
            "Epoch: 1775, Error: 0.017251357436180115\n",
            "Epoch: 1800, Error: 0.017105674371123314\n",
            "Epoch: 1825, Error: 0.016963785514235497\n",
            "Epoch: 1850, Error: 0.016825590282678604\n",
            "Epoch: 1875, Error: 0.016691002994775772\n",
            "Epoch: 1900, Error: 0.016559921205043793\n",
            "Epoch: 1925, Error: 0.016432268545031548\n",
            "Epoch: 1950, Error: 0.016307948157191277\n",
            "Epoch: 1975, Error: 0.016186924651265144\n",
            "Epoch: 2000, Error: 0.016069084405899048\n",
            "Epoch: 2025, Error: 0.015954365953803062\n",
            "Epoch: 2050, Error: 0.015842678025364876\n",
            "Epoch: 2075, Error: 0.015733931213617325\n",
            "Epoch: 2100, Error: 0.015628045424818993\n",
            "Epoch: 2125, Error: 0.015524912625551224\n",
            "Epoch: 2150, Error: 0.015424448996782303\n",
            "Epoch: 2175, Error: 0.015326529741287231\n",
            "Epoch: 2200, Error: 0.015231073834002018\n",
            "Epoch: 2225, Error: 0.015137976966798306\n",
            "Epoch: 2250, Error: 0.01504712924361229\n",
            "Epoch: 2275, Error: 0.01495841983705759\n",
            "Epoch: 2300, Error: 0.014871785417199135\n",
            "Epoch: 2325, Error: 0.014787102118134499\n",
            "Epoch: 2350, Error: 0.014704303815960884\n",
            "Epoch: 2375, Error: 0.014623278751969337\n",
            "Epoch: 2400, Error: 0.014543951489031315\n",
            "Epoch: 2425, Error: 0.014466223306953907\n",
            "Epoch: 2450, Error: 0.01439004298299551\n",
            "Epoch: 2475, Error: 0.01431534718722105\n",
            "Accuracy : 97.78506755828857\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}